{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cce13ac",
   "metadata": {},
   "source": [
    "Progetto: **Classificazione di testi descrittivi per destinazione d'uso, inerenti ai beni sottoposti ad aste giudiziarie italiane.**\n",
    "\n",
    "Studente: **Alessandro Monolo** | *10439147*\n",
    "\n",
    "Relatore: Marco Brambilla\n",
    "\n",
    "Referente aziendale: Simone Redaelli\n",
    "\n",
    "Master: Data Science & Artificial Intelligence\n",
    "\n",
    "Università: Politecnico di Milano\n",
    "\n",
    "<hr style=\"border:1px solid black\">\n",
    "\n",
    "## Fase di Preprocessing per il modello FastText e per i benchmark eseguiti con Word2Vec Tokenizer\n",
    "\n",
    "\n",
    "- **1.** **<u>Pre-Processing sulla variabile testuale:</u>**\n",
    "    - Per la fase di pre-processing sulla variabile testuale invece, ho eseguito i seguenti passaggi:\n",
    "        - **1.1** **Sostituisco tutti caratteri che non sono caratteri di parole, spazi, o singoli apici con spazi**;\n",
    "        - **1.2** **Elimino tutti i numeri presenti nella colonna testuale per FastText**;\n",
    "        - **1.3** **Elimino dopo aver controllato tutte le parole che sono sotto i due caratteri**;\n",
    "        - **1.4** **Elimino tutti i doppi spazi**;\n",
    "        \n",
    "\n",
    "- **2.** **<u>Filtro il data frame</u>**;\n",
    "\n",
    "\n",
    "- **3.** **<u>Conclusioni</u>**\n",
    "\n",
    "\n",
    "- **4.** **<u>Export final CSV</u>**\n",
    "\n",
    "\n",
    "<hr style=\"border:1px solid black\">\n",
    "\n",
    "**Importo le librerie che mi servono:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f58f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from matplotlib import cm\n",
    "from PIL import Image\n",
    "import string\n",
    "import unicodedata\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d056111",
   "metadata": {},
   "source": [
    "#### Set pandas options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aaadd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.display.max_rows = 5000\n",
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b70e184",
   "metadata": {},
   "source": [
    "**Importo file CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe04dc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\\\Master_Cefriel_DS_AI_Monolo\\\\0_Project_Work\\\\Dataset\\\\11_Dataset_TFIDF_LR_&_SVM\\\\Dataset_TFIDF_LR_&_SVM.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27088606",
   "metadata": {},
   "source": [
    "### 1 - Concludo la fase di preprocessing per il modello FastText:\n",
    "\n",
    "- **1.1 Sostituisco tutti caratteri che non sono caratteri di parole, spazi, o singoli apici con spazi:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec64a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_words_with_cypher(text):\n",
    "    return ' '.join(word for word in text.split() if not re.search(r'\\w*\\d\\w*', word))\n",
    "\n",
    "# Apply the function to the column\n",
    "df[\"Descrizione_Bene_FastText\"] = df[\"Descrizione_Bene_Lemm_Spacy\"].apply(remove_words_with_cypher)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28fb95f",
   "metadata": {},
   "source": [
    "- **1.2 Elimino tutti i numeri presenti nella colonna testuale per FastText:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87024b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    text = re.sub(r'[^\\w\\s\\']',' ', text)\n",
    "    return text\n",
    "\n",
    "df[\"Descrizione_Bene_FastText\"] = df[\"Descrizione_Bene_FastText\"].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab9474b",
   "metadata": {},
   "source": [
    "- **1.3 Elimino dopo aver controllato tutte le parole che sono sotto i due caratteri:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13f5524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisco una user defined function che sia in grado di eliminare tutte le parole composte da un singolo carattere:\n",
    "def filter_single_char_words(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if len(word) > 1]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Applico la user defined function alla colonna testuale pre-processata:\n",
    "df['Descrizione_Bene_FastText'] = df['Descrizione_Bene_FastText'].apply(filter_single_char_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290f1355",
   "metadata": {},
   "source": [
    "- **1.4 Elimino tutti i doppi spazi:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ae27120",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Descrizione_Bene_FastText\"] = df[\"Descrizione_Bene_FastText\"].apply(lambda x: ' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23faa5c3",
   "metadata": {},
   "source": [
    "### 2 - Filtro il data frame con solo le colonne che mi servono per la text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d04f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziono le colonne da eliminare\n",
    "columns_to_drop = [\"Descrizione_Bene_Pre_Process\",\n",
    "                   \"Descrizione_Bene_Lemm_Spacy\"]\n",
    "\n",
    "# Mantengo solo le colonne che mi servono per la text classification:\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d0f541",
   "metadata": {},
   "source": [
    "### 3 - Conclusioni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b36c95",
   "metadata": {},
   "source": [
    "- In questa **ultima fase di preprocessing** ho eliminato, partendo dalla variabile testuale pulita, preprocessata e lemmatizzata:\n",
    "    - Tutti i numeri;\n",
    "    - I caratteri ambigui;\n",
    "    - Doppi spazi;\n",
    "    - Stringhe con meno di due caratteri;\n",
    "- Ho quindi ridotto la variabile testuale a circa **39K** stringhe univoche contate.\n",
    "- Di conseguenza, la variabile ora pronta per il modello supervisionato **FastText**, risulta essere più scarna e pulita rispetto a quelle utlizzate con TFIDF e BoW."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2855df",
   "metadata": {},
   "source": [
    "### 4 - Export CSV Finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12053ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = df.to_csv(\"D:\\\\Master_Cefriel_DS_AI_Monolo\\\\0_Project_Work\\\\Dataset\\\\13_Dataset_FastText\\\\Dataset_FastText.csv\", \n",
    "                   index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
